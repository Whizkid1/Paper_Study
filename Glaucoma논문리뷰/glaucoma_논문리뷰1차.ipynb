{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "glaucoma_논문리뷰1차.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Whizkid1/Neural_Network_study/blob/main/glaucoma_%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B01%EC%B0%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global core.autocrlf true"
      ],
      "metadata": {
        "id": "zT_uNYk-RCQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 논문에 나온 정보를 토대로\n",
        "2. 내가 배운 부분을 토대로 \\\n",
        "논문 리뷰 1차 시도를 해보았다. \\\n",
        "작동 하는 것을 확인 \\\n",
        "다음 2차 시도에 제대로 구동시켜보면서 acc를 최대한 올려볼 것이다."
      ],
      "metadata": {
        "id": "bb5IBb30LoIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFo6Z3ySButR",
        "outputId": "b9955d9f-398a-43f9-e114-99a726b16f43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/dataset"
      ],
      "metadata": {
        "id": "QB4voNs9Cqc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -al \"/content/drive/MyDrive/Colab Notebooks/dataset/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqvu23-OBzhx",
        "outputId": "e322796d-6d95-45cd-a8f1-8d20112d7043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 472385\n",
            "-rw------- 1 root root 172964152 Dec 24 07:24 best_model.h5\n",
            "-rw------- 1 root root  62685307 Dec 24 06:51 flower_prepared.zip\n",
            "-rw------- 1 root root 124090252 Dec 29 07:49 galucoma.zip\n",
            "-rw------- 1 root root 123981705 Dec 29 06:40 raw_galucoma.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/Colab Notebooks/dataset/galucoma.zip\" -d /content/dataset"
      ],
      "metadata": {
        "id": "6p3d7ZgDBtWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.keras.applications.inception_v3.preprocess_input"
      ],
      "metadata": {
        "id": "A02pL8YwF6xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "input_tensor = Input(shape=(224, 224, 3))\n",
        "model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xldnVPmUDanv",
        "outputId": "f4715172-eb4d-4a11-d627-a5572eb85a9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
            "96116736/96112376 [==============================] - 4s 0us/step\n",
            "96124928/96112376 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import InceptionV3"
      ],
      "metadata": {
        "id": "09mIommdFd-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img , img_to_array\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "%matplotlib inline\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "FILE_DIR = \"/content/dataset/processed_data/\"\n",
        "\n",
        "\n",
        "preprocessor = preprocess_input\n",
        "\n",
        "train_data_generator = ImageDataGenerator(\n",
        "      rotation_range=10,\n",
        "      width_shift_range=0.1,\n",
        "      height_shift_range=0.1,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=False,\n",
        "      preprocessing_function=preprocessor,\n",
        "    #   validation_split= 0.2,\n",
        ").flow_from_directory(\n",
        "      FILE_DIR+\"train\",\n",
        "      target_size=(240,240),\n",
        "      batch_size=BATCH_SIZE,\n",
        "      class_mode='sparse'\n",
        ")\n",
        "\n",
        "valid_data_generator = ImageDataGenerator(\n",
        " preprocessing_function=preprocessor\n",
        ").flow_from_directory(\n",
        "      FILE_DIR+ \"valid\",\n",
        "      target_size=(240,240),\n",
        "      batch_size=BATCH_SIZE,\n",
        "      class_mode='sparse'\n",
        "     \n",
        ")\n",
        "\n",
        "test_data_generator = ImageDataGenerator(\n",
        "    preprocessing_function=preprocessor\n",
        "\n",
        ").flow_from_directory(\n",
        "      FILE_DIR+ \"test\",\n",
        "      target_size=(240,240),\n",
        "      batch_size=BATCH_SIZE,\n",
        "      class_mode='sparse'\n",
        "      \n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CK72zDc-Ek3x",
        "outputId": "f39215f9-be71-489c-a3a8-8c7b8f1390c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1230 images belonging to 3 classes.\n",
            "Found 160 images belonging to 3 classes.\n",
            "Found 154 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense,Flatten,BatchNormalization, Dropout,Conv2D, MaxPool2D, Activation, Input\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.initializers import GlorotNormal\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "initializer = GlorotNormal()\n",
        "# from keras import backend as K\n",
        "\n",
        "# 선행학습된 기준모델을 만듭니다\n",
        "preprocessor = preprocess_input\n",
        "\n",
        "\n",
        "conv_layers = InceptionV3(include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=(240,240,3),\n",
        "    pooling=None,\n",
        "    classes=1000)\n",
        "    #classifier_activation=\"softmax\")\n",
        "\n",
        "conv_layers.trainable = False\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "# model.add(conv_layers)\n",
        "# model.add(Input(input_shape = (240, 240, 3)))\n",
        "model.add(Conv2D(16, (20, 20),activation='relu', kernel_initializer=initializer)) #,input_shape=(240, 240, 3)\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPool2D((2,2),strides=2))\n",
        "model.add(Conv2D(32, (40, 40),activation='relu', kernel_initializer=initializer)) # ,input_shape=(110, 110, 16)\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPool2D((2,2),strides=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32,activation='relu',kernel_initializer=initializer))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64,activation='relu',kernel_initializer=initializer))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"Adagrad\", metrics=['acc'])\n"
      ],
      "metadata": {
        "id": "anVT2epUDaiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "      train_data_generator,\n",
        "      validation_data=valid_data_generator,\n",
        "      epochs=10\n",
        ")"
      ],
      "metadata": {
        "id": "niNDhSDiE5eX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "T1WHIemsE5ZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eVUdM2cdE5RK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T59eEafEBXou"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "from tensorflow.keras.applications import efficientnet\n",
        "from tensorflow.keras.applications import EfficientNetB2\n",
        "\n",
        "preprocessor = efficientnet.preprocess_input\n",
        "\n",
        "# conv_layers = EfficientNetB2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "# conv_layers.trainable = False\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "# model.add(conv_layers)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"RMSprop\", metrics=['acc'])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate(test_data_generator)\n",
        "print(\"loss=\", loss)\n",
        "print(\"acc=\", acc)\n",
        "\n",
        "\n",
        "\n",
        "batch_x, batch_y = test_data_generator.next()\n",
        "y_ = model.predict(batch_x)\n",
        "predicted = np.argmax(y_, axis=-1)\n",
        "\n",
        "plt.plot(batch_y[:100], \"o\")\n",
        "plt.plot(predicted[:100], '.')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "custom_labels = list(test_data_generator.class_indices.keys())\n",
        "print(\"label category index =\", batch_y[0])\n",
        "print(\"predicted category index =\", predicted[0])\n",
        "print(\"predicted category name =\", custom_labels[predicted[0]])\n"
      ]
    }
  ]
}